# Grounding DINO Inference Server Configuration

# Server settings
server:
  host: "0.0.0.0"
  port: 6061
  workers: 1
  log_level: "info"

# Model settings
model:
  config_file: "/resources/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py"
  checkpoint_path: "/resources/GroundingDINO/weights/groundingdino_swint_ogc.pth"
  device: "cuda"  # "cuda" or "cpu"

# Inference settings
inference:
  # Text prompt for bird detection
  text_prompt: "bird"

  # Detection thresholds
  box_threshold: 0.35      # Confidence threshold for bounding boxes
  text_threshold: 0.25     # Threshold for text matching

  # Image preprocessing
  max_image_size: 1333     # Maximum size for image resizing
  min_image_size: 800      # Minimum size for image resizing

  # Post-processing
  with_logits: true        # Include confidence scores in response

  # Image saving behavior
  save_images_without_detections: 0.8 # probability of saving images which do not have detections

# Storage settings (for LakeFS + MinIO)
storage:
  enabled: true            # Enable/disable image storage

  # MinIO settings (S3-compatible object storage)
  # Note: Credentials must be set via environment variables (see .env file)
  minio_endpoint: "minio:9000"           # Use "localhost:6076" when accessing from host
  minio_bucket_name: "bird-detection-images"       # Bucket name for image storage
  # Required env vars: MINIO_ROOT_USER, MINIO_ROOT_PASSWORD

  # LakeFS settings (data versioning)
  # Note: Credentials must be set via environment variables (see .env file)
  lakefs_host: "lakefs:8000"             # Use "localhost:6078" when accessing from host
  lakefs_repo_name: "bird-detection"     # Repository name for versioned data
  # Required env vars: LAKEFS_ACCESS_KEY, LAKEFS_SECRET_KEY

  # Commit settings (auto-versioning)
  commit_interval: 100     # Number of images to save before auto-commit (0 = disabled)
  daily_commit_hour: 18    # Hour (0-23) for scheduled daily commit
  daily_commit_minute: 0   # Minute (0-59) for scheduled daily commit

# Performance settings
performance:
  # Batch processing (future enhancement)
  batch_size: 1

  # Model optimization
  use_half_precision: false  # FP16 inference (requires GPU)
  compile_model: false       # PyTorch 2.0 compile (experimental)

# Monitoring
monitoring:
  enable_metrics: true
  # Metrics are exposed on the main server port at /metrics endpoint
